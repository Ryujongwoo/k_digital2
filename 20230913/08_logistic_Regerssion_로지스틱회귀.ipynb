{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a0d07e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\python\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "%config Completer.use_jedi = False\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95fcb8e",
   "metadata": {},
   "source": [
    "공부 시간, 과외 시간과 시험 성적 사이의 관계는 좌표로 나타냈을 때 형태가 직선으로 해결되는 선형 회귀를 사용하기에 적합했었다.  \n",
    "공부 시간에 따른 시험 점수가 아닌 합격 여부로 발표되는 시험이 있을 경우 직선으로 해결하기에는 적합하지 못한 문제가 발생된다.  \n",
    "이럴때 사용하는 로지스틱 회귀는 참과 거짓 중에 하나를 내놓는 과정으로 참과 거짓을 구분한 'S'자를 눕혀놓은 형태의 선을 그어주는 작업이다.\n",
    "\n",
    "<img src=\"./images/sigmoid.png\" width=\"800\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0f38ae",
   "metadata": {},
   "source": [
    "참조  \n",
    "http://taewan.kim/post/sigmoid_diff/  \n",
    "https://devlog.jwgo.kr/2018/04/16/sigmoid-graph-according-to-slope-change/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f1193b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "공부 시간: [2, 4, 6, 8, 10, 12, 14], 합격 여부: [0, 0, 0, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "data = [[2, 0], [4, 0], [6, 0], [8, 1], [10, 1], [12, 1], [14, 1]] # [x(공부 시간), y(합격 여부)]\n",
    "x = [i[0] for i in data] # 공부 시간\n",
    "y = [i[1] for i in data] # 합격 여부, 실제값\n",
    "print('공부 시간: {}, 합격 여부: {}'.format(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7dcd718b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a = [0.15448885], b = [0.76456446]\n"
     ]
    }
   ],
   "source": [
    "# 기울기 a와 y절편 b를 임의로 정한다.\n",
    "a = tf.Variable(tf.random_uniform([1], dtype=tf.float64))\n",
    "b = tf.Variable(tf.random_uniform([1], dtype=tf.float64))\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "print('a = {}, b = {}'.format(sess.run(a), sess.run(b)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c50753",
   "metadata": {},
   "source": [
    "시그모이드 방정식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ce52961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.e: 넘파이에서 지수 값(2.718281828459045)을 의미하는 상수\n",
    "# print(np.e)\n",
    "Y = 1 / (1 + np.e ** -(a * x + b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e88be7",
   "metadata": {},
   "source": [
    "시그모이드 방정식의 오차를 계산하는 수식을 만든다.  \n",
    "시그모이드 함수의 특성은 예측값(Y)이 항상 0아니면 1이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d6e9085",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = -tf.reduce_mean(np.array(y) * tf.log(Y) + (1 - np.array(y)) * tf.log(1 - Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ede7589",
   "metadata": {},
   "source": [
    "오차를 최소로 하는 값을 찾는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2c268a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_descent = tf.train.GradientDescentOptimizer(0.1).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042b62a8",
   "metadata": {},
   "source": [
    "학습 시킨다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d1d8324",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:      0, loss:  0.7358, a:  0.0768, b:  0.9512\n",
      "epoch:   5000, loss:  0.0585, a:  1.5525, b: -10.6794\n",
      "epoch:  10000, loss:  0.0372, a:  2.0063, b: -13.8782\n",
      "epoch:  15000, loss:  0.0275, a:  2.3156, b: -16.0512\n",
      "epoch:  20000, loss:  0.0218, a:  2.5529, b: -17.7163\n",
      "epoch:  25000, loss:  0.0180, a:  2.7458, b: -19.0691\n",
      "epoch:  30000, loss:  0.0154, a:  2.9083, b: -20.2088\n",
      "epoch:  35000, loss:  0.0134, a:  3.0488, b: -21.1934\n",
      "epoch:  40000, loss:  0.0119, a:  3.1725, b: -22.0599\n",
      "epoch:  45000, loss:  0.0106, a:  3.2829, b: -22.8334\n",
      "epoch:  50000, loss:  0.0097, a:  3.3826, b: -23.5319\n",
      "epoch:  55000, loss:  0.0088, a:  3.4734, b: -24.1685\n",
      "epoch:  60000, loss:  0.0081, a:  3.5569, b: -24.7532\n",
      "epoch:  65000, loss:  0.0075, a:  3.6341, b: -25.2938\n",
      "epoch:  70000, loss:  0.0070, a:  3.7059, b: -25.7964\n",
      "epoch:  75000, loss:  0.0066, a:  3.7729, b: -26.2660\n",
      "epoch:  80000, loss:  0.0062, a:  3.8358, b: -26.7066\n",
      "epoch:  85000, loss:  0.0058, a:  3.8951, b: -27.1216\n",
      "epoch:  90000, loss:  0.0055, a:  3.9511, b: -27.5137\n",
      "epoch:  95000, loss:  0.0052, a:  4.0041, b: -27.8854\n",
      "epoch: 100000, loss:  0.0050, a:  4.0546, b: -28.2386\n",
      "epoch: 105000, loss:  0.0047, a:  4.1026, b: -28.5751\n",
      "epoch: 110000, loss:  0.0045, a:  4.1485, b: -28.8964\n",
      "epoch: 115000, loss:  0.0043, a:  4.1924, b: -29.2038\n",
      "epoch: 120000, loss:  0.0042, a:  4.2345, b: -29.4984\n",
      "epoch: 125000, loss:  0.0040, a:  4.2749, b: -29.7813\n",
      "epoch: 130000, loss:  0.0038, a:  4.3137, b: -30.0533\n",
      "epoch: 135000, loss:  0.0037, a:  4.3512, b: -30.3153\n",
      "epoch: 140000, loss:  0.0036, a:  4.3872, b: -30.5679\n",
      "epoch: 145000, loss:  0.0034, a:  4.4221, b: -30.8119\n",
      "epoch: 150000, loss:  0.0033, a:  4.4558, b: -31.0477\n",
      "epoch: 155000, loss:  0.0032, a:  4.4883, b: -31.2759\n",
      "epoch: 160000, loss:  0.0031, a:  4.5199, b: -31.4969\n",
      "epoch: 165000, loss:  0.0030, a:  4.5505, b: -31.7113\n",
      "epoch: 170000, loss:  0.0029, a:  4.5803, b: -31.9194\n",
      "epoch: 175000, loss:  0.0029, a:  4.6091, b: -32.1215\n",
      "epoch: 180000, loss:  0.0028, a:  4.6372, b: -32.3180\n",
      "epoch: 185000, loss:  0.0027, a:  4.6645, b: -32.5092\n",
      "epoch: 190000, loss:  0.0026, a:  4.6911, b: -32.6953\n",
      "epoch: 195000, loss:  0.0026, a:  4.7170, b: -32.8767\n",
      "epoch: 200000, loss:  0.0025, a:  4.7422, b: -33.0535\n",
      "epoch: 205000, loss:  0.0024, a:  4.7669, b: -33.2260\n",
      "epoch: 210000, loss:  0.0024, a:  4.7909, b: -33.3944\n",
      "epoch: 215000, loss:  0.0023, a:  4.8144, b: -33.5588\n",
      "epoch: 220000, loss:  0.0023, a:  4.8374, b: -33.7195\n",
      "epoch: 225000, loss:  0.0022, a:  4.8598, b: -33.8767\n",
      "epoch: 230000, loss:  0.0022, a:  4.8818, b: -34.0304\n",
      "epoch: 235000, loss:  0.0021, a:  4.9033, b: -34.1808\n",
      "epoch: 240000, loss:  0.0021, a:  4.9243, b: -34.3281\n",
      "epoch: 245000, loss:  0.0020, a:  4.9449, b: -34.4723\n",
      "epoch: 250000, loss:  0.0020, a:  4.9651, b: -34.6137\n",
      "epoch: 255000, loss:  0.0020, a:  4.9849, b: -34.7523\n",
      "epoch: 260000, loss:  0.0019, a:  5.0043, b: -34.8882\n",
      "epoch: 265000, loss:  0.0019, a:  5.0234, b: -35.0216\n",
      "epoch: 270000, loss:  0.0019, a:  5.0420, b: -35.1525\n",
      "epoch: 275000, loss:  0.0018, a:  5.0604, b: -35.2810\n",
      "epoch: 280000, loss:  0.0018, a:  5.0784, b: -35.4071\n",
      "epoch: 285000, loss:  0.0018, a:  5.0961, b: -35.5311\n",
      "epoch: 290000, loss:  0.0017, a:  5.1135, b: -35.6529\n",
      "epoch: 295000, loss:  0.0017, a:  5.1306, b: -35.7727\n",
      "epoch: 300000, loss:  0.0017, a:  5.1475, b: -35.8904\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for epoch in range(300001):\n",
    "    sess.run(gradient_descent)\n",
    "    if epoch % 5000 == 0:\n",
    "        # print('epoch: {:6d}, loss: {:7.4f}, a: {:7.4f}, b: {:7.4f}'.format(epoch, sess.run(loss), sess.run(a)[0], sess.run(b)[0]))\n",
    "        print('epoch: %6d, loss: %7.4f, a: %7.4f, b: %7.4f' % (epoch, sess.run(loss), sess.run(a), sess.run(b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5af0f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80e1b19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60582fca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6e100f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
