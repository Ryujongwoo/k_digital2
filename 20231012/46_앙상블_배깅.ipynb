{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afae2edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe728d81",
   "metadata": {},
   "source": [
    "앙상블 학습은 크게 독립적 앙상블과 의존적 앙상블로 나눌 수 있다.\n",
    "\n",
    "독립적 앙상블(Independent Ensenble)  \n",
    "독립적 앙상블 방법에서 사용하는 개별 분류기들은 서로 독립적인 알고리즘이므로 각 분류기는 서로 다른 머신러닝 알고리즘을 사용할 수 있다. 각 분류기가 독립적이므로 효과적으로 병렬화 할 수 있다는 장점이 있다.\n",
    "\n",
    "의존적 앙상블(Dependent Ensenble)  \n",
    "의존적 앙상블 방법은 독립적 앙상블 방법과는 달리 개별 학습기들이 서로 독립이 아닌 경우를 의미하며 의존적 앙상블 방법 중 가장 유명한 방법은 부스팅이다.\n",
    "\n",
    "배깅(Bagging, Bootstrap aggregating)과 랜덤 포레스트(Random Forest)  \n",
    "배깅은 개별 분류기들의 결과를 종합하여 최종 분류기의 성능을 향상시키는 방법이다.  \n",
    "개별 분류기들이 동일한 트레이닝 데이터로 학습하는 보팅과는 달리 배깅은 오리지널 트레이닝 데이터셋에서 샘플(부트스트랩)을 뽑아 학습한다. 부트스트랩이란 중복을 허용한 랜덤 샘플 방식을 의미하고 개별 분류 모형의 결과값을 모아 다수결 투표를 통해 최종 예측하게 된다.  \n",
    "랜덤 포레스트는 여러 개의 개별 분류기인 의사 결정 트리를 토대로 예측한 결과를 종합해 전체 예측 정확도를 높이는 방법이다.\n",
    "\n",
    "랜덤 포레스트 알고리즘을 활용해 와인 데이터를 분류하는 모델을 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c78b8f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기\n",
    "from sklearn import datasets # 사이킷런이 제공하는 데이터셋을 사용하기 위해 import 한다.\n",
    "raw_wine = datasets.load_wine() # 와인 데이터를 불러온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "067315c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, 13)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 피쳐, 타겟 데이터 저장\n",
    "X = raw_wine.data # 피쳐 데이터를 저장한다.\n",
    "y = raw_wine.target # 타겟 데이터를 저장한다.\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06784142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 13) (133,) (45, 13) (45,)\n"
     ]
    }
   ],
   "source": [
    "# 트레이닝, 테스트 데이터 분할\n",
    "from sklearn.model_selection import train_test_split # 트레이닝, 테스트 데이터 분할을 위해 import 한다.\n",
    "X_tn, X_te, y_tn, y_te = train_test_split(X, y, random_state=0)\n",
    "print(X_tn.shape, y_tn.shape, X_te.shape, y_te.shape) # 트레이닝 데이터와 테스트 데이터로 분할한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e6955a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 표준화\n",
    "from sklearn.preprocessing import StandardScaler # 데이터 표준화를 위해 import 한다.\n",
    "std_scale = StandardScaler() # 표준화 스케일러 객체를 만든다.\n",
    "# 표준화는 트레이닝 데이터를 기반으로 실행하므로 트레이닝 피쳐 데이터 X_tn을 표준화 스케일러에 적합시킨다.\n",
    "X_tn_std = std_scale.fit_transform(X_tn) # 트레이닝 데이터를 적합 후 표준화 한다.\n",
    "X_te_std = std_scale.transform(X_te) # 테스트 데이터를 표준화 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "94871967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=2, random_state=0)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 생성 후 데이터 학습\n",
    "from sklearn.ensemble import RandomForestClassifier # 랜덤 포레스트 알고리즘을 사용하기 위해 import 한다.\n",
    "# 너무 깊게 학습하면 과적합이 발생될 수 있으므로 max_depth 옵션을 지정해서 과적합을 방지한다.\n",
    "clf_rf = RandomForestClassifier(max_depth=2, random_state=0) # 랜덤 포레스트 모델을 만든다.\n",
    "# 표준화된 트레이닝 피쳐 데이터 X_tn_std와 트레이닝 타겟 데이터 y_tn를 모델에 넣어서 랜덤 포레스트 알고리즘을 학습시킨다.\n",
    "clf_rf.fit(X_tn_std, y_tn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1c38da2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 1 0 1 1 0 2 1 1 2 2 0 1 2 1 0 0 2 0 0 0 0 1 1 1 1 1 1 2 0 0 1 0 0 0 2\n",
      " 1 1 2 0 0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터 예측\n",
    "# 표준화된 테스트 데이터 X_te_std로 예측한다.\n",
    "pred_rf = clf_rf.predict(X_te_std)\n",
    "print(pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1ca45f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9555555555555556\n"
     ]
    }
   ],
   "source": [
    "# 정확도 평가\n",
    "from sklearn.metrics import accuracy_score # 모델의 정확도를 평가하기 위해 import 한다.\n",
    "# accuracy_score() 메소드의 인수로 실제 타겟 데이터(y_te)와 예측된 데이터(pred_rf)를 넘겨 정확도를 계산한다.\n",
    "accuracy = accuracy_score(y_te, pred_rf)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "67fe12bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94117647 1.         0.88888889]\n"
     ]
    }
   ],
   "source": [
    "# 정밀도 평가\n",
    "from sklearn.metrics import precision_score # 모델의 정밀도를 평가하기 위해 import 한다.\n",
    "# precision_score() 메소드의 인수로 실제 타겟 데이터(y_te)와 예측된 데이터(pred_rf)를 넘겨 정밀도를 계산한다.\n",
    "precision = precision_score(y_te, pred_rf, average=None)\n",
    "print(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8bc79403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.        0.9047619 1.       ]\n"
     ]
    }
   ],
   "source": [
    "# 재현율 평가\n",
    "from sklearn.metrics import recall_score # 모델의 재현율를 평가하기 위해 import 한다.\n",
    "# recall_score() 메소드의 인수로 실제 타겟 데이터(y_te)와 예측된 데이터(pred_rf)를 넘겨 재현율를 계산한다.\n",
    "recall = recall_score(y_te, pred_rf, average=None)\n",
    "print(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8ce04036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96969697 0.95       0.94117647]\n"
     ]
    }
   ],
   "source": [
    "# f1 score 평가\n",
    "from sklearn.metrics import f1_score # 모델의 f1 score를 평가하기 위해 import 한다.\n",
    "# f1_score() 메소드의 인수로 실제 타겟 데이터(y_te)와 예측된 데이터(pred_rf)를 넘겨 f1 score를 계산한다.\n",
    "f1 = f1_score(y_te, pred_rf, average=None)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "de72fb6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16  0  0]\n",
      " [ 1 19  1]\n",
      " [ 0  0  8]]\n"
     ]
    }
   ],
   "source": [
    "# 혼돈 행렬 확인\n",
    "from sklearn.metrics import confusion_matrix # 혼돈 행렬을 만들기 위해 import 한다.\n",
    "# confusion_matrix() 메소드의 인수로 실제 타겟 데이터(y_te)와 예측된 데이터(pred_rf)를 넘겨 혼돈 행렬을 만든다.\n",
    "conf_matrix = confusion_matrix(y_te, pred_rf)\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e621da01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class_0       0.94      1.00      0.97        16\n",
      "     class_1       1.00      0.90      0.95        21\n",
      "     class_2       0.89      1.00      0.94         8\n",
      "\n",
      "    accuracy                           0.96        45\n",
      "   macro avg       0.94      0.97      0.95        45\n",
      "weighted avg       0.96      0.96      0.96        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 분류 리포트 확인\n",
    "from sklearn.metrics import classification_report # 분류 리포트를 출력하기 위해 import 한다.\n",
    "# classification_report() 메소드의 인수로 실제 타겟 데이터(y_te)와 예측된 데이터(pred_rf)를 넘겨 분류 리포트를 만든다.\n",
    "target_names = raw_wine.target_names\n",
    "class_report = classification_report(y_te, pred_rf, target_names=target_names)\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ae310d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
