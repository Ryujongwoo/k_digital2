GET _cat
# 모든 인덱스 보기
GET _cat/indices
GET _cat/indices?v

# 인덱스(테이블) 만들기
# PUT 인덱스이름
PUT index1
PUT index2
# 개별 인덱스 확인하기
# GET 인덱스이름
GET index1
GET index2
# 개별 인덱스 삭제하기, 인덱스가 삭제되면서 저장된 모든 도큐먼트도 같이 삭제된다.
# DELETE 인덱스이름
DELETE index1
DELETE index2

# 인덱스를 만들면서 데이터 입력하기
# 인덱스가 없으면 인덱스를 만들고 도큐먼트를 입력하고 인덱스가 있으면 기존
# 인덱스에 도큐먼트를 입력한다.
# 도큐먼트를 인덱스에 포함(저장)시키는 것을 인덱싱이라고 한다.
# 도큐먼트는 JSON 형식으로 입력한다.
# PUT 인덱스이름/_doc/아이디
PUT index2/_doc/1
{
  "name": "mike",
  "age": 25,
  "gender": "male"
}

# 기존 인덱스에 도큐먼트 입력하기
# 기존에 없던 country 필드를 추가하고 기존에 있던 age, gender 필드는 사용하지
# 않았지만 문제없이 추가된다.
PUT index2/_doc/2
{
  "name": "kim",
  "country": "france"
}

# 잘못된 도큐먼트 입력하기
# age 필드는 long 타입으로 매핑되었는데 text 타입으로 입력했다.
# 관계형 데이터베이스라면 오류가 발생했겠지만 유연하게 대응하는 엘라스틱서치는
# 타입을 변환해서 저장한다.
PUT index2/_doc/3
{
  "name": "jane",
  "age": "20",
  "gender": "female"
}

# 아이디를 이용해서 인덱스에 저장된 개별 도큐먼트 조회하기
# GET 인덱스이름/_doc/아이디
GET index2/_doc/1
GET index2/_doc/2
GET index2/_doc/3

# 엘라스틱서치가 제공하는 쿼리(DSL, Domain Specific Language)를 이용해 도큐먼트
# 조회하기
# 인덱스에 저장된 모든 도큐먼트를 읽어오기
GET index2/_search

# 도큐먼트 수정하기
# PUT 인덱스이름/_doc/아이디
# PUT 명령을 존재하지 않는 아이디로 실행하면 도큐먼트가 입력되고 존재하는
# 아이디로 실행하면 도큐먼트가 수정된다.
PUT index2/_doc/1
{
  "name": "park",
  "age": 45,
  "gender": "female"
}

# PUT 명령으로 도큐먼트를 수정하면 기존에 저장된 모든 필드가 삭제되고 새로
# 입력하는 내용으로 도큐먼트가 덮어쓰기가 된다.
PUT index2/_doc/2
{
  "name": "hong"
}

# POST 명령으로 도큐먼트를 수정하면 저장되어있던 모든 데이터는 그대로 유지되고
# 수정하는 데이터만 수정된다.
# POST 인덱스이름/_update/아이디
# {} 내부에 바로 수정하려는 내용을 쓰면 안되고 doc 블록을 만들고 doc 블록
# 내부에 수정할 내용을 써야한다.
POST index2/_update/3
{
  "doc": {
    "name": "choi"
  }
}

# 아이디를 이용해서 인덱스에 저장된 개별 도큐먼트 삭제하기
# DELETE 인덱스이름/_doc/아이디
DELETE index2/_doc/2

# 벌크(더미) 데이터
# 도큐먼트 CRUD 동작을 할 때 REST API를 호출해 하나하나 도큐먼트를 요청하는 
# 것 보다 벌크로 한 번에 요청하는 것이 효율적이다.
# 벌크는 도큐먼트 읽기는 지원하지 않고 생성, 수정, 삭제만 지원한다.
# 벌크 데이터 형식은 삭제(delete)는 한 줄로 작성하고 나머지 작업(index, create,
# update)은 두 줄로 작성한다.

# 벌크 데이터 입력하기
# POST _bulk
# {"index": {"_index": "인덱스이름", "_id": "아이디"}}
# {"field": "value", ...}
# index는 벌크 데이터로 입력되는 아이디가 존재하면 기존 데이터를 수정한다.
POST _bulk
{"index": {"_index": "index2", "_id": "4"}}
{"name": "kang", "age": 30, "gender": "male"}

# POST _bulk
# {"create": {"_index": "인덱스이름", "_id": "아이디"}}
# {"field": "value", ...}
POST _bulk
{"create": {"_index": "index2", "_id": "5"}}
{"name": "song", "age": 35, "gender": "female"}
# create는 벌크 데이터로 입력되는 아이디가 존재하면 에러가 발행된다.

# 벌크 데이터 수정하기
# POST _bulk
# {"update": {"_index": "인덱스이름", "_id": "아이디"}}
# {"doc": {"field": "value", ...}}
POST _bulk
{"update": {"_index": "index2", "_id": "4"}}
{"doc": {"name": "jang"}}

# 벌크 데이터 삭제하기
# POST _bulk
# {"delete": {"_index": "인덱스이름", "_id": "아이디"}}
POST _bulk
{"delete": {"_index": "index2", "_id": "5"}}

GET index2/_doc/4
GET index2/_doc/5

# 매핑(Mapping)
# 관계형 데이터베이스의 스키마와 같은 역할을 하는 것을 매핑이라 한다.
# 엘라스틱서치가 검색 엔진으로 전문 검색과 대용량 데이터를 빠르게 실시간 검색할
# 수 있는 이유는 매핑이 있기 때문인데 매핑을 엘라스틱서치가 자동으로 하면
# 다이나믹(오토) 매핑이라 하고, 사용자가 직접 설정하면 명시적 매핑이라 한다.
# 엘라스틱서치는 문자열 타입을 text와 keyword 타입으로 나눌 수 있는데, 전문
# 검색을 활용하려면 이 두 가지 타입을 이해하고 있어야 한다.

# 인덱스 매핑 정보만 확인하기
GET index2/_mapping

# 인덱스를 만들면서 명시적 매핑 지정하기
# PUT index3
# {
#   "mappings": {
#     "properties": {
#       "필드이름": {
#         "type": "필드타입"
#       }
#       , ...
#     }
#   }
# }

PUT index3
{
  "mappings": {
    "properties": {
      "name" : {
        "type" : "text"
      },
      "age": {
        "type": "short"
      },
      "gender": {
        "type": "keyword"
      }
    }
  }
}
GET index3/_mapping
DELETE index3

# 다이나믹 매핑 타입
# boolean(논리값), float(실수), long(정수), object(객체), text/keyword(문자열)

# 명시적 매핑 타입
# 텍스트
#   text: 전문 검색, 텍스트 분석기가 텍스트를 작은 단위(단어)로 분리한다.
#   keyword: 정렬 또는 집계, 텍스트를 분리하지 않고 원문을 통째로 인덱싱한다.
# 날짜
#   date: 날짜/시간 데이터
# 부호있는 정수(고정 소수점)
#   byte: 8비트, -128 ~ 127
#   short: 16비트, -32768 ~ 32767
#   integer: 32비트, -2147483648 ~ 2147483647
#   long: 64비트, -2^63 ~ 2^63 - 1
# 실수(부동/유동 소수점)
#   scaled float: float 데이터의 특정 값을 곱해서 정수형으로 바꾼 데이터
#   half_float: 16비트 실수
#   float: 32비트 실수
#   double: 64비트 실수
# 논리
#   boolean: true 또는 false만 값으로 가진다.
# IP 주소
#   ip: ipv4 또는 ipv6 타입의 ip 주소를 입력한다.
# 위치 정보
#   geo-point: 하나의 위치 포인트(위도, 경도)
#   geo-shape: 하나의 위치 포인트가 아닌 임의의 지형
# 범위 설정
#   integer_range, long_range: 정수형 범위
#   float_range, double_range: 실수형 범위
#   ip_range: ip 주소 범위
#   date_range: 날자 범위
# 객체형
#   object: 계층 구조를 가지는 형태로 필드 안에 다른 필드들이 들어갈 수 있다.
# 배열형
#   nested: 배열형 객체
#   join: 부모/자식 관계를 표현할 수 있다.

# text 타입
# 일반적으로 문장을 저장하는 매핑 타입으로 사용된다.
# 무조건적인 강제성은 없지만 일반적으로 문장 또는 여러 단어가 나열되는 문자열은
# text 타입으로 지정한다.

POST _analyze
{
  "analyzer": "standard",
  "text": "We offer solutions for enterprise search, observability, and security that are built on a single, flexible technology stack that can be deployed anywhere"
}

# text 타입으로 지정된 문자열은 분석기(analyzer)에 의해 토큰(token)으로 분리되고
# 분리된 토큰들은 인덱싱되는데 이를 역인덱싱(inverted indexing)이라 한다. 이때,
# 역인덱스에 저장된 토큰들을 용어(term)라고 한다.

# text 타입을 가지는 인덱스 생성
PUT text_index
{
  "mappings": {
    "properties": {
      "contents": {
        "type": "text"
      }
    }
  }
}
GET text_index/_mapping

PUT text_index/_doc/1
{
  "contents": "beautiful day"
}
GET text_index/_doc/1

PUT text_index/_doc/2
{
  "contents": "beautiful today"
}
GET text_index/_doc/2

# text_index 인덱스에 match라는 전문 검색 쿼리 실행
GET text_index/_search
{
  "query": {
    "match": {
      "contents": "day"
    }
  }
}

# keyword 타입을 가지는 인덱스 생성
PUT keyword_index
{
  "mappings": {
    "properties": {
      "contents": {
        "type": "keyword"
      }
    }
  }
}
GET keyword_index/_mapping

PUT keyword_index/_doc/1
{
  "contents": "beautiful day"
}
GET keyword_index/_doc/1

PUT keyword_index/_doc/2
{
  "contents": "beautiful today"
}
GET keyword_index/_doc/2

# keyword_index 인덱스에 match라는 전문 검색 쿼리 실행
GET keyword_index/_search
{
  "query": {
    "match": {
      "contents": "day"
    }
  }
}

# 멀티 타입 필드
# 멀티 타입 필드는 단일 필드 입력에 대해 여러 하위 필드를 정의한다.
# 문자열의 경우 전문 검색이 필요하면서 정렬 또는 집계로 필요한 경우가 있다.
# 멀티 타입 필드를 만들기 위해서는 fields라는 파라미터를 사용한다.

# 멀티 타입 필드를 가지는 가지는 인덱스 생성
PUT multifield_index
{
  "mappings": {
    "properties": {
      "message": {
        "type": "text"
      },
      "contents": {
        "type": "text",
        "fields": {
          "keyword": {
            "type": "keyword"
          }
        }
      }
    }
  }
}
# message 필드는 단일 타입 필드이고 contents 필드는 멀티 타입 필드로 설정했다.
# contents 필드는 text 타입이면서 keyword 타입을 가진다.
# fields라는 파라미터에 "keyword"라는 필드 이름을 사용했는데 반드시 "keyword"
# 라는 필드 이름을 사용하지 않고 "abc"와 같은 필드 이름을 사용해도 무관하지만
# 통상적으로 "keyword"라는 필드 이름을 많이 사용한다.
GET multifield_index/_mapping
DELETE multifield_index

PUT multifield_index/_doc/1
{
  "message": "1 document",
  "contents": "beautiful day"
}
GET multifield_index/_doc/1

PUT multifield_index/_doc/2
{
  "message": "2 document",
  "contents": "beautiful today"
}
GET multifield_index/_doc/2

PUT multifield_index/_doc/3
{
  "message": "3 document",
  "contents": "wonderful day"
}
GET multifield_index/_doc/3

PUT multifield_index/_doc/4
{
  "message": "4 document",
  "contents": "beautiful today"
}
GET multifield_index/_doc/4
GET multifield_index/_search

# multifield_index 인덱스에 match라는 전문 검색 쿼리 실행
GET multifield_index/_search
{
  "query": {
    "match": {
      "message": "document"
    }
  }
}

GET multifield_index/_search
{
  "query": {
    "match": {
      "contents": "beautiful"
    }
  }
}

# multifield_index 인덱스에 term라는 용어 검색 쿼리 실행
# 이번에는 contents 필드의 keyword 타입으로 검색해보자. keyword 타입은 contents
# 필드의 하위 필드이므로 조금 다른 방식의 접근이 필요하다.
# "contents"는 contents 필드를 의미하므로 contents 뒤에 keyword를 추가해서
# "contents.keyword"를 사용하면 하위 필드를 참조할 수 있다.
GET multifield_index/_search
{
  "query": {
    "term": {
      "contents.keyword": "beautiful today"
    }
  }
}

# multifield_index 인덱스에 aggs라는 집계 쿼리 실행
GET multifield_index/_search
{
  "aggs": {
    "contents": {
      "terms": {
        "field": "contents.keyword",
        "size": 10
      }
    }
  }
}
# "contents.keyword"로 지정했으므로 값이 같은 데이터끼리 그룹화가 된다.
# "size"는 집계를 계산하는데 사용된 데이터를 출력할 개수를 지정한다.

# 인덱스 템플릿
# 설정이 동일한 인덱스를 매번 일일이 작성하는 것은 비효율적일 뿐만 아니라
# 실수를 유발할 수 있기 때문에 인덱스 템플릿은 주로 설정이 동일한 복수의
# 인덱스를 만들 때 사용한다.

# 모든 인덱스 템플릿을 확인한다.
GET _index_template
# 특정 인덱스 템플릿을 확인한다.
# GET _index_template/인덱스템플릿이름
GET _index_template/ilm-history
# 확인할 인덱스 템플릿 이름에 와일드카드 문자(*)를 사용할 수 있다.
GET _index_template/.ml*

# 인덱스 템플릿 만들기
# PUT _index_template/인덱스템플릿이름
# {
#   mappings과 settings을 사용해서 인덱스 템플릿 설정 정의
# }

# 인덱스 템플릿의 매핑이 적용되지 않은 인덱스 => 다이나믹 매핑이 적용된다.
PUT test_index1
GET test_index1
DELETE test_index1

PUT test_index1/_doc/1
{
  "name": "kim",
  "age": 99,
  "gender": "male"
}
GET test_index1/_doc/1
GET test_index1/_mapping

# index_patterns 파라미터
# 새로 만들어지는 인덱스 중에 인덱스 이름이 지정한 인덱스 패턴과 매칭되는
# 경우 이 템플릿을 적용한다.
# 인덱스 템플릿을 만들기 전에 존재하던 인덱스들은 새로 작성된 인덱스 템플릿의
# index_patterns 파라미터에 지정된 패턴과 이름이 일치하더라도 인덱스 템플릿이
# 적용되지 않는다.
# 즉, 인덱스 템플릿이 생성된 시점 이후에 작성되는 인텍스에 인덱스 템플릿이
# 적용된다.
# priority 파라미터
# 인덱스 생성시 인덱스 이름에 매칭되는 인덱스 템플릿이 2개 이상일 경우 인덱스
# 템플릿이 적용되는 우선순위를 정한다. 숫자가 높은 템플릿이 먼저 적용된다.
# template 파라미터
# 새로 생성되는 인덱스에 적용되는 mappings과 settings을 설정한다.
PUT _index_template/test_template
{
  "index_patterns": ["test_*"],
  "priority": 1,
  "template": {
    "settings": {
      "number_of_shards": 3,
      "number_of_replicas": 1
    },
    "mappings": {
      "properties": {
        "name": {"type": "text"},
        "age": {"type": "short"},
        "gender": {"type": "keyword"}
      }
    }
  }
}
GET _index_template/test_template
GET _index_template/test_*

# 인덱스 템플릿 삭제하기
# DELETE _index_template/인덱스템플릿이름
DELETE _index_template/test_template

# 인덱스 템플릿의 매핑이 적용된 인덱스
PUT test_index2
GET test_index2
DELETE test_index2

PUT test_index2/_doc/1
{
  "name": "kim",
  "age": 99,
  "gender": "male"
}
GET test_index2/_doc/1
GET test_index2/_mapping

# 인덱스 템플릿의 index_patterns과 일치하지 않으면 인텍스 템플릿이 적용되지
# 않는다. => 다이나믹 매핑이 적용된다.
PUT testindex2
GET testindex2
DELETE testindex2

PUT testindex2/_doc/1
{
  "name": "kim",
  "age": 99,
  "gender": "male"
}
GET testindex2/_doc/1
GET testindex2/_mapping

# 인덱스 템플릿이 적용된 인덱스에 인덱스 템플릿 매핑값과 다른 데이터가 입력되면
# mapper_parsing이 가능하면 에러가 발생되지 않지만 불가능하면 에러가 발생된다.
PUT test_index2/_doc/2
{
  "name": "lee",
  "age": "99",
  "gender": "female"
}
# "99"는 short 타입으로 mapper_parsing이 가능하므로 정상적으로 처리된다.
GET test_index2/_doc/2
GET test_index2/_mapping

PUT test_index2/_doc/3
{
  "name": "choi",
  "age": "99 years",
  "gender": "male"
}
# "99 years"는 short 타입으로 mapper_parsing이 불가능하므로 에러가 발생된다.

# priority에 지정한 인덱스 템플릿 적용 우선순위 확인
PUT _index_template/multi_template1
{
  "index_patterns": ["multi_*"],
  "priority": 1,
  "template": {
    "mappings": {
      "properties": {
        "age": {"type": "integer"},
        "name": {"type": "text"}
      }
    }
  }
}
DELETE _index_template/multi_template1

PUT _index_template/multi_template2
{
  "index_patterns": ["multi_data_*"],
  "priority": 2,
  "template": {
    "mappings": {
      "properties": {
        "age": {"type": "short"},
        "name": {"type": "keyword"}
      }
    }
  }
}
DELETE _index_template/multi_template2

GET _index_template/multi_*

# 만들려는 인덱스 이름이 multi_data_index이므로 multi_template1 인텍스 템플릿의
# 인텍스 패턴 "multi_*"에 해당되고 multi_template2 인텍스 템플릿의 인덱스 패턴
# "multi_data_*"에도 해당된다.
PUT multi_data_index
DELETE multi_data_index
# multi_template1는 priority가 1이고 multi_template2는 priority가 2로 설정되었기
# 때문에 priority가 크게 지정된 multi_template2가 적용된다.
GET multi_data_index/_mapping

# 만들려는 인덱스 이름이 multi_sample_index이므로 multi_template1 인덱스
# 템플릿의 인텍스 패턴 "multi_*"에 해당되고 multi_template2 인텍스 템플릿의
# 인덱스 패턴 "multi_data_*"에는 해당되지 않되기 때문에 priority와 상관없이
# multi_template1가 적용된다.
PUT multi_sample_index
GET multi_sample_index/_mapping

# 다이나믹 템플릿
# 다이나믹 템플릿은 매핑을 다이나믹하고 지정하는 템플릿 기술로 로그 시스템같은
# 비정형화된 데이터는 데이터의 구조를 알지 못하기 때문에 필드 타입을 정확히 
# 정의하기 힘들고 필드의 개수를 정할 수 없는 경우도 있다.
# 다이나믹 템플릿은 매핑을 정확하게 할 수 없거나 대략적인 데이터 구조만 알고
# 있을 때 사용할 수 있는 방법이다.

# 다이나믹 매핑을 적용한 인덱스 생성
# 인덱스 만들 때 dynamic_templates를 추가하면 다이나믹 템플릿을 추가할 수 있다.
# my_string_fields는 사용자가 임의로 정한 다이나믹 템플릿의 이름이다.
# match_mapping_type 파라미터
# 다이나믹 템플릿을 적용할 데이터 유형을 지정해서 다이나믹 매핑의 조건 역할을
# 한다.
PUT dynamic_index1
{
  "mappings": {
    "dynamic_templates": [
      {
        "my_string_fields": {
          "match_mapping_type": "string",
          "mapping": {"type": "keyword"}
        }
      }
    ]
  }
}
GET dynamic_index1/_mapping
DELETE dynamic_index1

# 문자열과 숫자 데이터를 넣어서 다이나믹 템플릿 매핑 결과를 확인한다.
PUT dynamic_index1/_doc/1
{
  "name": "kim",
  "age": 20
}
GET dynamic_index1/_doc/1

PUT dynamic_index1/_doc/2
{
  "name": "lee",
  "age": "30",
  "gender": "male"
}
GET dynamic_index1/_doc/2

# ========================================================================

# match 파라미터
# 필드 이름이 패턴과 일치할 경우 매핑 타입으로 변경한다.
# unmatch 파라미터
# match 패턴과 일치하는 경우에 제외할 패턴을 설정한다.
PUT dynamic_index2
{
  "mappings": {
    "dynamic_templates": [
      {
        "my_long_fields": {
          "match": "long_*",
          "unmatch": "*_text",
          "mapping": {"type": "integer"}
        }
      }
    ]
  }
}
DELETE dynamic_index2
GET dynamic_index2/_mapping

# 필드 이름에 따른 다이나믹 템플릿 매핑 결과를 확인한다.
# long_num 필드는 match에 적어준 패턴에 매칭되므로 integer 타입으로 매칭된다.
PUT dynamic_index2/_doc/1
{
  "long_num": "5"
}
GET dynamic_index2/_doc/1

# long_text 필드는 match에 적어준 패턴에 매칭되지만 unmatch에 적어준 패턴에
# 매칭되기 때문에 integer 타입으로 매칭되지 않고 멀티 필드로 다이나맥 매칭된다.
PUT dynamic_index2/_doc/2
{
  "long_num": "50",
  "long_text": "100"
}
GET dynamic_index2/_doc/2

# 분석기
# 엘라스틱서치는 전문 검색을 지원하기 위해 역인덱싱 기술을 사용한다.
# 문자열을 토큰화(단어 단위로 나눈다.)하고 인덱싱하는데 이를 역인덱싱이라 한다.
# 책의 앞부분의 목차와 달리 책 뒷부분에는 단어가 책의 몇 페이지에 나와있는지
# 알려주는 색인(인덱스, 찾아보기)을 역인덱싱이라 보면된다.
# 분석기는 역인덱싱을 지원하기 위해서 캐릭터 필터, 토크나이저, 토큰 필터로
# 구성된 분석기 모듈을 가지고 있고 토크나이저는 반드시 포함해야 한다.
# 분석기는 토크나이저를 이용해 필터링된 문자열을 자르게 되는데, 이때 잘린 단위를
# 토큰이라 하고 이러한 토큰들은 복수의 토큰 필터를 거치며 정제된 후 최종적으로
# 역인덱스에 저장되는 상태의 토근을 용어(term)라고 한다.

# 캐릭터 필터
# 입력받은 문자열을 변경하거나 불필요한 문자들을 제거한다.
# 토크나이저
# 문자열을 토큰으로 분리한다. 분리할 때 토큰의 순서나 시작, 끝 위치도 기록한다.
# 토큰 필터
# 분리된 토큰 필터 작업을 한다. 대소문자 구분, 형태소 분석 등의 작업을 한다.

# 분석기 사용법은 analyzer 파라미터에 사용할 분석기를 입력하고 text 파라미터에
# 분석할 문자열을 입력하면 된다.
# stop, standard, simple, whitespace 분석기가 있다.

# whitespace 분석기
# 공백을 경계로 문장을 토큰화 하고 화이트 스페이스(\n)는 토큰화하지 않는다.
POST _analyze
{
  "analyzer": "whitespace",
  "text": "The 10 most\n loving\n dog breeds."
}
# token: [The, 10, most, loving, dog, breeds.]

# standard 분석기
# 특별한 설정이 없을 경우 엘라스틱서치가 기본적으로 사용하는 분석기이다.
# 영문법을 기준으로 한 standard 토크나이저와 소문자 변경 필터가 포함되어 있다.
# 공백을 경계로 문장을 토큰화하고 모든 대문자를 소문자로 변경한다.
# 화이트 스페이스(\n), 특수문자는 토큰화하지 않는다.
POST _analyze
{
  "analyzer": "standard",
  "text": "The 10 most loving dog breeds."
}
# [the, 10, most, loving, dog, breeds]

# simple 분석기
# standard 분석기의 기능을 포함하고 있고 숫자는 토큰화하지 않는다.
POST _analyze
{
  "analyzer": "simple",
  "text": "The 10 most loving dog breeds."
}
# [the, most, loving, dog, breeds]

# stop 분석기
# simple 분석기의 기능을 포함하고 있고 스톱 필터가 포함되어 있어서 "the"와 같은
# 불용어가 제거된다.
# 스톱 필터는 불용어(데이터 집합에 출현하는 빈도는 매우 높지만 의미가 없는 단어)
# 처리를 한다.
POST _analyze
{
  "analyzer": "stop",
  "text": "The 10 most loving dog breeds."
}
# [most, loving, dog, breeds]

# 토크나이저
# 토크나이저는 문자열을 분리해 토큰화하는 역할을 한다. 분석기에 반드시 포함되야
# 하기 때문에 형태에 맞는 토크나이저 선택이 중요하다.

# standard 토크나이저
# standard 분석기가 사용하는 토크나이저로 특별한 설정이 없으면 기본 토크나이저로
# 사용된다.
POST _analyze
{
  "tokenizer": "standard",
  "text": "email: Elastic@lk-Company.com"
}
# [email, Elastic, lk, Company.com]

# lowercase 토크나이저
# 토큰화한 결과를 모두 소문자로 변경한다.
POST _analyze
{
  "tokenizer": "lowercase",
  "text": "email: Elastic@lk-Company.com"
}
# [email, elastic, lk, company, com]

# uax_url_email 토크나이저
# url이나 email을 토근화하는데 강점이 있다.
POST _analyze
{
  "tokenizer": "uax_url_email",
  "text": "email: Elastic@lk-Company.com"
}
# [email, elastic, lk, company, com]

# 필터
# 분석기는 하나의 토크나이저와 다수의 필터로 조합된다.
# 분석기에서 필터는 옵션으로 하나 이상을 포함할 수 있지만, 없어도 분석기를
# 돌리는데 문제가 발생되지는 않는다.
# 필터가 없는 분석기는 토크나이저만 이용해서 토큰화 작업을 진행하는데,
# 엘라스틱서치에서 제공하는 분석기들은 하나 이상의 필터를 포함하고 있고 필터를
# 통해 더 세부적인 작업이 가능하다.
# 필터는 단독으로 사용할 수 없고 반드시 토크나이저가 있어야 한다.

POST _analyze
{
  "tokenizer": "standard",
  "text": "The 10 most loving dog breeds."
}
# [The, 10, most, loving, dog, breeds]

# lowercase 필터는 모든 대문자를 소문자로 변경한다.
POST _analyze
{
  "tokenizer": "standard",
  "filter": ["lowercase"], 
  "text": "The 10 most loving dog breeds."
}
# [the, 10, most, loving, dog, breeds]

# uppercase 필터는 모든 소문자를 대문자로 변경한다.
POST _analyze
{
  "tokenizer": "standard",
  "filter": ["uppercase"], 
  "text": "The 10 most loving dog breeds."
}
# [THE, 10, MOST, LOVING, DOG, BREEDS]

# stemmer 필터는 영어 문법을 분석하는 필터로 한글에서는 동작하지 않는다.
# 언어마다 고유한 문법이 있어서 필터 하나로 모든 언어에 대응하기는 힘들다.
# 한글의 경우 아리랑, 노리 같은 오픈소스 필터가 있다.
POST _analyze
{
  "tokenizer": "standard",
  "filter": ["stemmer"], 
  "text": "The 10 most loving dog breeds."
}
# [The, 10, most, love, dog, breeds]

# 커스텀 분석기
# 커스텀 분석기는 엘라스틱서치에서 제공하는 내장 분석기들 중 원하는 기능을
# 만족하는 분석기가 없을 때 사용자가 직접 토크나이저, 필터 등을 조합해서
# 사용할 수 있는 분석기다.

# 커스텀 분석기를 적용한 인덱스 만들기
# settings 파라미터에 analysis 파라미터를 추가하고 analysis 파라미터 내부에
# filter 파라미터로 사용자 정의 필터와 analyzer 파라미터로 사용자 정의 분석기를
# 지정해서 만든다.
# analyzer 파라미터 내부에 분서기 이름(my_analyzer)을 지정하고 type을 custom으로
# 설정하면 커스텀 분석기라는 것을 의미한다.
# 분석기에는 반드시 토크나이저(tokenizer)가 들어가야 하고 standard 토크나이저로
# 지정했다.
# 필터는 선택적인 사항이고 캐릭터 필터(char_filter)와 토큰 필터(filter)를 지정
# 할 수 있다. 캐릭터 필터는 사용하지 않을 것이므로 []만 입력했고 토큰 필터는 
# 엘라스틱이 제공하는 lowercase와 사용자 정의 필터인 my_stopwords 2개를 사용하기
# 위해서 ","로 구분해서 필터를 나열했다.
# stop 필터는 엘라스틱서치가 제공하는 불용어를 제외한 추가적인 불용어가 필요할
# 때 filter 파리미터에 필터 이름(my_stopwords)을 지정하고 type 파라미터에 stop
# stopwords 파라미터어 추가 불용어를 입력해서 만든다.
PUT customer_analyzer
{
  "settings": {
    "analysis": {
      "filter": {
        "my_stopwords": {
          "type": "stop",
          "stopwords": ["lions", "cats"]
        }
      },
      "analyzer": {
        "my_analyzer": {
          "type": "custom",
          "char_filter": [],
          "tokenizer": "standard",
          "filter": ["lowercase", "my_stopwords"]
        }
      }
    }
  }
}
GET customer_analyzer
DELETE customer_analyzer

# customer_analyzer 커스텀 분석기 테스트
GET customer_analyzer/_analyze
{
  "analyzer": "my_analyzer",
  "text": "Cats Lions Dogs"
}
