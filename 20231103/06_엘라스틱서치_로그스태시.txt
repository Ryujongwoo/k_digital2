로그스태시
로그란 컴퓨터 시스템에서 시스템의 일련의 동작을 기록하는 것으로 로그는 성능, 오류, 동작 과정 등의 중요한 정보를 담고 있다.
로그는 형태가 표준화되어 있지 않기 때문에 로그 생산자는 제각각 다양한 방법으로 로그를 생성한다.
로그라는 것은 반정형(완벽하게 일치하지는 않더라도 어느 정도 형태가 있는) 데이터이며 세상의 모든 것이 로그가 될 수 있기 때문에
로그를 강제할 방법도 없기 때문에 로그를 수집하는 쪽에서 로그의 형태를 분석하고 시스템이 인식할 수 있도록 정제하는 작업이 
필요한데 로그스태시는 로그를 수집해서 가공하고 전송하는 일련의 과정을 간편하게 구현하기 위한 기능을 제공한다.

로그스태시는 플러그인 기반의 오픈 소스 데이터 처리 파이프라인 도구이다.
다소 복잡하고 귀찮은 데이터 전처리 과정을 별도의 애플리케이션 작성 없이 비교적 간단한 설정만으로 수행할 수 있다.
데이터를 저장하기 전에 사용자가 원하는 형태로 변경할 수 있는 기능을 제공한다.

로그스태시 실행
로그스태시가 설치된 폴더 아래 bin 폴더의 logstash.bat 파일을 실행하면 된다.
로그스태시를 실행하기 위해서는 반드시 파이프라인 설정이 필요하다.
파이프라인은 별도의 설정 파일을 만들어 기록하거나 config 폴더의 pipelines.yml 파일에 기록한다.

-e 옵션을 사용하면 콘솔에서 직접 파이프라인을 설정할 수 있다.
운영체제의 표준 입력(stdin)으로 전달받은 메시지를 표준 출력(stdout)으로 표시한다.
--log.level error은 로그 중 error 레벨 미만의 로그를 감추는 설정이다.
.\bin\logstash.bat -e "input { stdin {} } output { stdout {} }" --log.level error

실행중인 로그스태시는 ctrl + C를 누르면 종료된다.

파이프라인
로그스태시에서 가장 중요한 부분으로 데이터를 입력받아 실시간으로 변경하고 이를 다른 시스템에 전달한다.
파이프라인은 입력, 출력은 필수 구성 요소, 필터는 선택사항 이고 각 단계에서 여러개의 플러그인을 포함 시킬 수 있다.
source data => logstash pipeline(input => filter => output) => elastic search

파이프라인 형식
input {
  {
    입력 플러그인(stdin, file, syslog, kafka, jdbc, ...)
  }
}

filter {
  {
    필터 플러그인(grok, dissect, mutate, date, ...)
  }
}

output {
  {
    출력 플러그인(stdout, elasticsearch, file, kafka, ...)
  }
}

config 폴더에 logstash-test.conf 라는 이름의 설정 파일을 만든다.
입력으로 file 플러그인, 출력으로 stdout 플러그인을 사용했다.
path 옵션은 읽어들일 파일의 위치를 지정한다. 파일에 로그가 쌓이면 실시간으로 파일의 변경된 부분을 감지해 읽어들인다.
start_position 옵션은 최초로 파일을 발견했을 때 파일을 읽을 위치를 지정한다.

=======================================================================================================
logstash-test.conf 파일의 내용
=======================================================================================================
input {
  file {
    path => "C:/k_digital/elasticStack/elasticsearch-7.17.14/logs/elasticsearch.log"
    start_position => "beginning"
  }
}

output {
  stdout { }
}
=======================================================================================================

-f 옵션은 logstash-test.conf 파일을 파이프라인 설정에 사용한다는 의미이다.
.\bin\logstash.bat -f .\config\logstash-test.conf --log.level error

필터
입력 플러그인이 받은 데이터를 의미있는 데이터로 구조화하는 역할을 한다.
필수 구성요소가 아니어서 필터 없이 파이프라인을 구성할 수 있지만 필터가 없는 파이프라인은 기능을 온전히 발휘하지 못한다.

실습을 위한 간단한 예제 로그 파일(filter-example.log)을 만든다.
=======================================================================================================
filter-example.log 파일의 내용
=======================================================================================================
[2023-11-01 12:52:12] [ID1] 192.168.0.7 9500 [INFO] - connected.
[2023-11-01 12:58:47]   [ID2] 218.35.17.184 1004 [warn] - busy server
=======================================================================================================

=======================================================================================================
logstash-test.conf 파일의 내용 수정
path 옵션 수정, sincedb_path 옵션 추가
sincedb_path 옵션 값을 "nul"로 지정하면 sincedb 데이터베이스 파일을 만들지 않기 때문에 이전 파일을 읽었던 기록이 없어서
매번 로그스태시를 실행할 때 마다 처음부터 파일을 읽는다.
sincedb 데이터베이스 파일은 파일을 어디까지 읽었나 기록하는 파일이다.
=======================================================================================================
input {
  file {
    path => "C:/k_digital/elasticStack/logstash-7.17.14/filter-example.log"
    start_position => "beginning"
    sincedb_path => "nul"
  }
}

output {
  stdout { }
}
=======================================================================================================

.\bin\logstash.bat -f .\config\logstash-test.conf --log.level error

mutate 필터 - 문자열 자르기(split)
데이터나 로그는 대부분 길이가 길기때문에 우리가 원하는 형태로 분리해야 한다.

=======================================================================================================
logstash-test.conf 파일의 내용 수정
filter 추가
mutate: 필드를 변형하는 다양한 기능을 제공한다.
split 옵션은 구분자를 기준으로 문자열을 배열 형태로 나눈다.
=======================================================================================================
input {
  file {
    path => "C:/k_digital/elasticStack/logstash-7.17.14/filter-example.log"
    start_position => "beginning"
    sincedb_path => "nul"
  }
}

filter {
  mutate {
    split => {"message" => " "}
  }
}

output {
  stdout { }
}
=======================================================================================================

mutate 플러그인의 옵션 및 적용 순서
coerce: null인 필드 값에 넣어줄 기본값을 지정한다.
rename: 필드 이름을 바꾼다.
replace: 필드 값을 특정 값으로 바꾼다.
gsub: 정규식 패턴이 일치하는 문자열을 다른 문자열로 대체한다.
uppercase: 필드 값을 모두 대문자로 변경한다.
lowercase: 필드 값을 모두 소문자로 변경한다.
strip: 필드 값의 좌우 공백을 제거한다.
join: 구분자를 지정해서 하나의 문자열로 합친다.
split: 구분자를 기준으로 문자열을 배열 형태로 나눈다.
merge: 특정 필드에 다른 필드를 포함시킨다.

=======================================================================================================
logstash-test.conf 파일의 내용 수정
필터 플러그인 공통 옵션 추가
add_field 옵션은 새로운 필드를 추가한다.
split 옵션의 구분자에 의해 구분되어 배열 형태가된 데이터에 특정 인덱스에 접근하려면 [필드이름][인덱스]와
같이 접근하면 되고 특정 인덱스의 값을 얻어오려면 %{[필드이름][인덱스]}와 같이 사용한다.
remove_field 옵션은 특정 필드를 삭제한다.
=======================================================================================================
input {
  file {
    path => "C:/k_digital/elasticStack/logstash-7.17.14/filter-example.log"
    start_position => "beginning"
    sincedb_path => "nul"
  }
}

filter {
  mutate {
    split => {"message" => " "}
    add_field => {"id" => "%{[message][2]}"}
    remove_field => "message"
  }
}

output {
  stdout { }
}
=======================================================================================================

=======================================================================================================
logstash-test2.conf 파일의 내용
filter 추가
dissect: mapping 옵션에 구분자 형태를 지정해서 필드를 구분한다.

%{필드명}와 같이 작성하면 %{}안의 필드명으로 새로운 필드가 만들어지고 %{} 외부의 문자들은 모두 구분자가 된다.
[%{timestamp}]%{?->}[%{id}] %{ip} %{port} [%{level}] - %{message}.
[2023-11-01 12:52:12] [ID1] 192.168.0.7 9500 [INFO] - connected.
[2023-11-01 12:58:47]   [ID2] 218.35.17.184 1004 [warn] - busy server

[%{timestamp}]와 [%{id}] 사이에는 공백이 1칸인 경우와 공백이 3칸인 경우가 있다.
구분자를 만들 때 [%{timestamp}]와 [%{id}] 사이에 공백을 1칸을 주면 공백이 3칸인 로그에서 에러가 발생된다.
_dissectfailure 메시지는 dissect 플러그인이 에러가 발생되는 경우 표시된다.
이 문제를 해결하려면 공백이 몇 칸이 나오던지 공백을 무시하게 하면된다.
%{?->}로 지정하면 연속되는 여러 공백들을 무시한다.
=======================================================================================================
input {
  file {
    path => "C:/k_digital/elasticStack/logstash-7.17.14/filter-example.log"
    start_position => "beginning"
    sincedb_path => "nul"
  }
}

filter {
  dissect {
    mapping => {"message" => "[%{timestamp}]%{?->}[%{id}] %{ip} %{port} [%{level}] - %{message}"}
  }
}

output {
  stdout { }
}
=======================================================================================================

=======================================================================================================
logstash-test3.conf 파일의 내용
%{?필드명}과 같이 필드명 앞에 "?"를 붙여거나 %{}만 입력하면 결과에 포함시키지 않는다.
%{+필드명}과 같이 필드명 앞에 "+"를 붙이면 %{}에 매핑된 내용을 "+"뒤에 지정한 필드에 붙인다.
%{ip} %{port} => ip 필드와 port 필드가 별도로 생성된다.
%{ip} %{+ip} => ip 필드의 값 뒤에 port 번호를 붙인다.
=======================================================================================================
input {
  file {
    path => "C:/k_digital/elasticStack/logstash-7.17.14/filter-example.log"
    start_position => "beginning"
    sincedb_path => "nul"
  }
}

filter {
  dissect {
    mapping => {"message" => "[%{timestamp}]%{?->}[%{id}] %{ip} %{+ip} [%{?level}] - %{}"}
  }
}

output {
  stdout { }
}
=======================================================================================================

=======================================================================================================
logstash-test4.conf 파일의 내용
filter 추가
grok: match 옵션에 정규 표현식 패턴을 지정해서 문자열을 파싱한다.
grok은 자주 사용하는 정규 표현식을 패턴화해놨으며 이 패턴을 이용해 %{패턴이름:필드명} 형태로 사용한다.
grok에 사용하는 정규 표현식 패턴 이름은 아래의 주소를 참조한다.
https://github.com/logstash-plugins/logstash-patterns-core/blob/main/patterns/ecs-v1/grok-patterns

NUMBER: 십진수를 인식한다. 부호와 소수점도 포함한다.
SPACE: 공백, 탭 등 하나 이상의 공백을 인식한다.
URI: URI를 인식한다. 프로토콜, 인증 정보, 호스트, 경로, 파라미터를 포함 할 수 있다.
IP: IP 주소를 인식한다. IPv4, IPv6를 모두 인식할 수 있다.
SYSLOGBASE: 시스로그 포맷에서 타임스템프, 중요도, 호스트, 프로세스 정보까지 인식한다.
TIMESTAMP_ISO8601: ISO8601 표준의 타임스템프를 인식한다. 2023-11-02T12:23:27+09:00의 형태이다.
DATA: 이 패턴의 직전 패턴부터 다음 패턴 사이를 모두 인식한다.

\[%{TIMESTAMP_ISO8601:timestamp}\]와 \[%{DATA:id}\] 사이에는 공백이 1칸인 경우와 공백이 3칸인 경우가 있다.
정규 표현식 패턴을 사용할 때 \[%{TIMESTAMP_ISO8601:timestamp}\]와 \[%{DATA:id}\] 사이에 공백을 1칸을 주면 
공백이 3칸인 로그에서 에러가 발생된다.
_grokparsefailure 메시지는 grok 플러그인이 에러가 발생되는 경우 표시된다.
이 문제를 해결하려면 공백이 몇 칸이 나오던지 공백을 무시하게 하면된다.
[ ]*로 지정하면 연속되는 여러 공백들을 무시한다.

"[", "]", "-", "." 같은 기호는 역슬래시(\)를 붙여서 사용해야 한다.
NUMBER:ports의 결과를 엘라스틱서치에 저장하면 문자열 타입으로 인식된다. 정수 타입으로 엘라스틱서치에 저장할 때
인식하게 하려면 NUMBER:ports:int와 같이 :int를 추가하면 된다.
=======================================================================================================
input {
  file {
    path => "C:/k_digital/elasticStack/logstash-7.17.14/filter-example.log"
    start_position => "beginning"
    sincedb_path => "nul"
  }
}

filter {
  grok {
    match => {"message" => "\[%{TIMESTAMP_ISO8601:timestamp}\] [ ]*\[%{DATA:id}\] %{IP:ip} %{NUMBER:port} \[%{LOGLEVEL:level}\] \- %{DATA:msg}\."}
  }
}

output {
  stdout { }
}
=======================================================================================================

=======================================================================================================
logstash-test5.conf 파일의 내용
TIMESTAMP_ISO8601 grok 정규식 패턴의 내용은 아래와 같고 년, 월, 일 구분자로 "-"만 허용한다.
%{YEAR}-%{MONTHNUM}-%{MONTHDAY}[T ]%{HOUR}:?%{MINUTE}(?::?%{SECOND})?%{ISO8601_TIMEZONE}?
따라서 2023-11-02은 정상 처리되지만 2023/11/02과 같이 입력하면 "/" 때문에 에러가 발생된다.
날짜/시간 데이터 정규식 패턴은 로그를 만드는 사용자가 다양한 형태로 만들어 사용하기 때문에 데이터를 수집하는
쪽에서 반드시 패턴을 통일시켜야 한다. => 사용자 정의 패턴을 만든다.
pattern_definitions 옵션을 사용해서 년-월-일 형태와 년/월/일 형태의 패턴을 모두 사용할 수 있도록 정의한다.

년, 월, 일을 "-" 또는 "/"를 사용해 구분하려면 [/-], [-/] 패턴 모두 사용이 가능하다.
년, 월, 일을 구분하는데 "-" 또는 "/"를 사용하지 않고 "."를 사용할 경우 pattern_definitions에 "."도 추가해야 한다.
"."는 정규 표현식에 아무 문자나 1개와 대응되는 약속된 기능이므로 "."를 문자로 인식하게 하려면 "\\."로 사용해야 한다.
"-"가 [] 중간에 있으면 ~ 부터 ~ 까지의 의미가 있으므로 [] 중간에 용할 때는 "\-"로 사용해야 한다.
=======================================================================================================
input {
  file {
    path => "C:/k_digital/elasticStack/logstash-7.17.14/filter-example.log"
    start_position => "beginning"
    sincedb_path => "nul"
  }
}

filter {
  grok {
    pattern_definitions => {"MY_TIMESTAMP" => "%{YEAR}[/\-\\.]%{MONTHNUM}[-/\\.]%{MONTHDAY}[T ]%{HOUR}:?%{MINUTE}(?::?%{SECOND})?%{ISO8601_TIMEZONE}?"}
    match => {"message" => "\[%{TIMESTAMP_ISO8601:timestamp}\] [ ]*\[%{DATA:id}\] %{IP:ip} %{NUMBER:port} \[%{LOGLEVEL:level}\] \- %{DATA:msg}\."}
  }
}

output {
  stdout { }
}
=======================================================================================================

=======================================================================================================
logstash-test6.conf 파일의 내용
대소문자 변경: uppercase, lowercase
uppercase, lowercase 옵션으로 대문자 또는 소문자로 변경할 필드는 []안에 ""로 묶어서 입력하면 되고
대문자 또는 소문자로 변경할 필드가 2개 이상이라면 ["level", "msg"]와 같이 입력하면 된다.
=======================================================================================================
input {
  file {
    path => "C:/k_digital/elasticStack/logstash-7.17.14/filter-example.log"
    start_position => "beginning"
    sincedb_path => "nul"
  }
}

filter {
  dissect {
    mapping => {"message" => "[%{?timestamp}]%{?->}[%{?id}] %{?ip} %{?port} [%{level}] - %{msg}"}
  }
  mutate {
    uppercase => ["msg"]
    lowercase => ["level"]
  }
}

output {
  stdout { }
}
=======================================================================================================

=======================================================================================================
logstash-test7.conf 파일의 내용
filter 추가
date: 날짜/시간 데이터의 서식을 지정한다.
날짜/시간 서식은 아래의 주소를 참조한다.
https://www.joda.org/joda-time/apidocs/org/joda/time/format/DateTimeFormat.html
=======================================================================================================
input {
  file {
    path => "C:/k_digital/elasticStack/logstash-7.17.14/filter-example.log"
    start_position => "beginning"
    sincedb_path => "nul"
  }
}

  dissect {
    mapping => {"message" => "[%{timestamp}]%{?->}[%{?id}] %{?ip} %{?port} [%{?level}] - %{?msg}"}
  }
  mutate {
    strip => "timestamp"
  }
  date {
    match => ["timestamp", "YYYY-MM-dd HH:mm", "YYYY/MM/dd HH:mm:ss", "YYYY.MM.dd HH:mm"]
    target => "my_timestamp"
    timezone => "UTC"
  }

output {
  stdout { }
}
=======================================================================================================

=======================================================================================================
logstash-test8.conf 파일의 내용
조건문을 이용한 필터: if ~ else
if 조건식 {
  조건이 참일 경우 실행할 내용
} else {
  조건이 거짓일 경우 실행할 내용
}
조건식에 사용하는 필드 이름은 []안에 입력하면 되고 이 때, 필드명 앞뒤에 따옴표는 쓰지 않는다.
=======================================================================================================
input {
  file {
    path => "C:/k_digital/elasticStack/logstash-7.17.14/filter-example.log"
    start_position => "beginning"
    sincedb_path => "nul"
  }
}

filter {
  dissect {
    mapping => {"message" => "[%{timestamp}]%{?->}[%{id}] %{ip} %{port} [%{level}] - %{msg}"}
  }
  if [level] == "error" {
    drop {}
  }
  else if [level] == "warn" {
    mutate {
      remove_field => ["@version", "@timestamp", "path", "message", "host", "msg", "timestamp", "port"]
      add_field => {"레벨이" => "error는 아닌데 warn인 경우"}
    }
  } else {
    mutate {
      remove_field => ["@version", "@timestamp", "path", "message", "host", "level", "timestamp", "port"]
      add_field => {"레벨이" => "error도 아니고 warn도 아닌 경우"}
    }
  }
}

output {
  stdout { }
}
=======================================================================================================

=======================================================================================================
logstash-test9.conf 파일의 내용
출력 플러그인
=======================================================================================================
input {
  file {
    path => "C:/k_digital/elasticStack/logstash-7.17.14/filter-example.log"
    start_position => "beginning"
    sincedb_path => "nul"
  }
}

filter {
  mutate {
    # 로그스태시 파이프라인 파일에 "#"으로 시작하는 문장은 주석으로 처리된다.
    # uppercase => ["message"]
  }
}

output {
  # stdout { }
  
}
=======================================================================================================


















